# Kafka入门
Kafka将消息系统、存储系统、流处理系统组合在一起，构成了以Kafka为中心的流式数据处理平台，它既能处理最新的实时数据，也能处理过去的历史数据。
Kafka作为流式数据平台的核心组件，主要包括下面4种核心的API，
* 生产者（producer），应用程序发布事件流到Kafka的一个或多个主题
* 消费者（consumer），应用程序订阅Kafka的一个或多个主题，并处理事件流
* 连接器（connector），将Kafka主题和已有数据源进行连接，数据可以互相导入和导出
* 流处理（processor），从Kafka主题消费输入流，经过处理后，产生输出流到相应主题

![](./doc.img/kafka-apis.png)

建立以Kafka为核心的流式数据管道，不仅要保证低延迟的消息处理，还需要保证数据存储的可靠性。另外，在和离线系统集成时，将Kafka的数据加载到批处理系统时，
要保证数据不遗漏；Kafka集群的某些节点在停机维护时，要保证集群可用。
## Kafka的基本概念
### 分区模型
Kafka集群由多个消息代理服务器（broker server）组成，发布到Kafka集群的每条消息都有一个topic。通常不同应用产生不同类型的数据，可以设置不同的主题。
一个主题一般会有多个消息订阅者，当生产者发布消息到某个主题时，订阅了这个主题的消费者都可以接收到生产者写入的新消息。

Kafka集群为每个topic维护了分布式的分区（partition）日志文件，物理层面上可以把主题看作分区的日志文件（partitioned log）。每个分区都是一个有序的、
不可变的记录序列，新的消息会不断追加到提交日志（commit log）。分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，叫做偏移量（offset），
这个偏移量能够唯一地定位当前分区的每一条消息。

如下图所示，主题有3个分区，每个分区的偏移量从0开始，不同分区的偏移量是独立的，不会相互影响。发布到Kafka的每条消息包括键值和时间戳。消息到达服务器的指定分区后，
都会分配到一个自增的偏移量。原始的消息内容和分配的偏移量以及其它一些元数据信息都会存储在分区日志文件中。消息的键可以不用设置，这种情况下消息会均衡地分布到不同的分区。

![](./doc.img/kafka-log_anatomy.png)

### 消费模型
消息由生产者发布到Kafka集群后，会被消费者消费。消息的消费模型有两种：推送模型（push）和拉取模型（pull）。基于推送模型的消息系统，由消息代理记录消息的消费情况。
消息代理在将消息推送到消费者后，标记这条消息为已消费，但是这种方式无法很好地保证消息的处理语义。比如，消息代理把消息发送出去后，当消费进程挂掉或者由于网络原因没有收到这条消息时，就有可能造成消息丢失。
如果要保证消息的处理语义，消息代理发送完消息后，要设置状态为“已发送”，只有收到消费者的确认请求后才更新为“已消费”，这就需要在消息代理中记录所有消息的消费状态，这种做法也是不可取的。

Kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序读取每个分区的消息。消费者拉取的最大上限通过最高水位（watermark）控制，
生产者最新写入的消息如果还没有到达备份数量，对消费者是不可见的。这种由消费者控制偏移量的优点是：消费者可以按照任意的顺序消费消息。比如，消费者可以重置
到旧的偏移量，重新处理之前已经消费过的消息，或者直接跳到最近的位置，从当前时刻开始消费。

Kafka会将生产者发布的所有消息保存在Kafka集群中，不管消息有没有被消费。用户可以设置保留时间来清理过期的数据，比如，设置保留策略为两天。那么，在消息发布之后，
它可以被不同的消费者消费，在两天之后，过期的消息就会向动清理掉。
### 分布式模型
Kafka每个主题的多个分区日志分布式地存储在Kafka集群上，同时为了故障容错，每个分区都会有副本在其它的代理节点。其中一个节点会作为主副本（leaader），其它节点叫做从副本（follower）。
主副本会负责所有的客户端读写操作，从副本仅仅从主副本复制数据。当主副本出现故障时，其中一个从副本会被选举成为新的主副本。因为每个分区的副本中只有主副本接受读写，
所以每个服务端都会作为某些分区的主副本，以及另外一些分区的备份副本，这样Kafka集群的所有服务端整体上对客户端是负载均衡的。

Kafka的生产者发布消息到服务端的指定主题，会指定消息所属的分区，生产者发布消息时根据消息是否有键，采用不同的分区策略。消息没有键时，通过轮询方式进行客户端负载均衡；
消息由键时，根据分区语义确保相同键的消息总是发送到同一个分区。

Kafka的消费者通过订阅主题来消费消息，并且每个消费者都会设置一个消费组名称。因为生产者发布到主题的每一条消息都只会发送给消费组的一个消费组。所以，如果要实现传统消息系统的“队列”模型，
可以让每个消费组属于同一个消费组，这样消息就会负载均衡到所有的消费者；如果要实现“发布－订阅”模型，则每个消费者的消费组名称都不相同，这样每条消息就会广播给所有的消费组。

![](./doc.img/kafka-consumer-groups.png)

同一消费组下多个消费组互相协调消费工作，Kafka会将所有的分区平均地分配给所有的消费者，这样每个消费者都可以分配到数量均等的分区。Kafka的消费组管理协议
会动态地维护消费组的成员列表，当一个新的消费组加入消费组，或者有消费者离开消费组，都会触发再平衡操作。

Kafka只保证在一个分区内消息的有序性，并不保证同一个主题多个分区的消息顺序。而且，消费者读取一个分区消息的顺序和生产者写入到这个分区的顺序是一致的。
比如，生产者写入“hello”和“kafka”两条消息到分区P1，则消费者读取到的顺序也一定是“hello”和“kafka”。如果业务上需要保证所有消息完全一致，只能通过设置一个分区，
但这种做法的缺点是最多只能有一个消费组来进行消费。一般来说，只需要保证每个分区的有序性，再对消息加上键来保证相同键的所有消息落入到同一个分区，就可以满足绝大多数的应用。

## Kafka的设计思路
### 持久化和数据传输
现代的操作系统针对磁盘的读写做了一些优化措施来加快访问。比如，**预读（read-ahead）** 会提前将一个比较大的磁盘块写入内存。**后写（write-behind）** 
会将很多小的逻辑写操作合并为一个大的物理写操作。并且，操作系统还会将主内存剩余空间都用作磁盘缓存。所有的磁盘读写操作都会经过统一的磁盘缓存（除了直接I/O会绕过磁盘缓存）。
综合这几点，针对磁盘的顺序访问，有可能比随机的内存访问更快。

应用程序将数据写入文件系统的一般做法是，在内存中保存尽可能多的数据，并在需要时将这些数据刷新到文件系统。但是Kafka做了完全相反的事，立即将数据写入文件系统的持久化日志文件，
但不进行刷盘的系统调用。数据首先会被传输到磁盘缓存，操作系统随后会将这些数据定期自动刷新到物理磁盘。

生产者如果每发送一条信息都直接通过网络发送到服务器，势必会造成过多的网络请求。如果我们能够将多条消息按照分区进行分组，并采用批量的方式一次发送一个消息集，
并且对消息集进行压缩，就可以减少网络传输的带宽，进一步提高数据的传输效率。

消费者要读取服务端的数据，需要将服务端的磁盘文件通过网络发送到消费者进程。传统读取磁盘文件的数据在每次发送到网络时，需要以下几步：
1. 操作系统从磁盘读数据，写入内核空间的页缓存
2. 应用程序从内核空间读数据，写入用户空间的缓冲区
3. 应用程序将数据写回内核空间的套接字缓冲区
4. 操作系统将数据从套接字缓冲区复制到网卡接口，然后数据通过网络发送出去

显而易见，这里发生了四次数据拷贝和两次系统调用。通过使用sendfile，能将数据拷贝次数降至一次，这就是所谓的零拷贝技术（更多请参考[零拷贝](../操作系统、网络/零拷贝.md)）。

### 生产者和消费者
#### 负载均衡
Kafka的生产者将消息直接发送给分区主副本所在的消息代理节点，并不需要经过任何的中间路由层。为了做到这一点，所有的消息代理节点都会保存一份相同的元数据，
这份元数据记录了所有主题分区对应的主副本节点。生产者在发送信息之前，会向任意一个代理节点请求一份元数据，并确定每条消息对应的目标节点，然后把消息直接发生给对应的目标节点。

生产者决定消息被发送到哪个分区，一般有两种方式：通过随机方式将请求负载到不同的消息代理节点，或者使用一些分区语义函数。
Kafka暴露了分区语义的接口允许用户指定消息的键如何分区。
#### 异步发送
前面提到生产者通过异步批量发送消息的方式解决了网络请求过多的问题。生产者试图在内存中收集尽可能多的数据，然后再一次请求中发送一批数据，这样服务端的I/O操作也会降低。
并且我们可以配置消息数量上限和延迟时间上限，通过牺牲一点延迟来换取更高的吞吐量。
#### 消费者的拉取模型
普通的拉取消息模型有一个缺点，如果代理节点没有数据，消费者就需要不断的轮询来等待新数据的到来。解决方法是：允许消费者的拉取请求以阻塞式、长轮询的方式等待，
直到有新的数据到来。还可以为消费者设置“指定的字节数量”，表示消息代理在还没有收集足够的数据时，拉取请求就不会立即返回。

### 副本机制和容错处理
Kafka对每一个主题分区进行复制（可以指定复制因子），从副本会保持和主副本的数据同步，在主副本失效时可以替换主副本。

通过将分区的主副本均匀地分配在各个服务器上来实现负载均衡。

从副本始终尽量保持和主副本的数据同步。从副本的日志和主副本的日志总是相同的，它们都有相同的偏移量和相同顺序的消息。从副本从主副本消费信息的方式和普通的消费者一样，
只不过从副本会将消息运用到自己的本地日志文件。

分布式系统处理故障容错时，需要明确地定义节点是否处于存活状态。Kafka对节点的存活定义有两个条件：
1. 节点必须和zookeeper保持会话
2. 如果该节点是某分区的从副本，其复制进度不能落后太多

满足这两个条件，叫做"正在同步中（in sync）"。每个分区的主副本会跟踪正在同步中的从副本节点（In Sync Replicas，ISR）。如果一个从副本挂掉、没有响应或者落后太多，
主副本就会将其从 ISR 中移除，反之，如果从副本重新赶上主副本，它就会加入 ISR。

在Kafka中，一条消息只有被 ISR 集合的所有副本都写入本地的日志文件，才会被认为消息被成功提交了。任何时刻，只要 ISR 至少有一个副本是存活的，
Kafka就可以保证“一条消息一旦被提交，就不会丢失”。只有已经提交的消息才能被消费者消费，因此消费者不用担心会看到因为主副本失败而丢失的消息。